#!/usr/bin/env node
import "zx/globals";
import runDownRmWatermark from "../lib/down-rm-watermark.mjs";
import runHistoryPerson from "../lib/history-person/history-person.mjs";
import runAiRemoveWatermark from "../lib/ai-remove-watermark.mjs";
import runMergeVideo from "../lib/merge-video.mjs";
import runClipAudio from "../lib/clip-audio.mjs";
import runClipVideo from "../lib/clip-video.mjs";
import runAutoDeepseekJimeng, {
  clearBrowserData,
} from "../lib/auto-deepseek-jimeng/auto-deepseek-jimeng.mjs";
import { runJimengVideoFlow } from "../lib/auto-deepseek-jimeng/jimeng-video-generator.mjs";
import runFilter, { listFilters } from "../lib/filter.mjs";
import runConvert3D, { list3DModes } from "../lib/convert-3d.mjs";
import runBatchCropImages from "../lib/batch-crop-images.mjs";
import runExtractAudio, {
  showExtractAudioHelp,
} from "../lib/extract-audio.mjs";
import runMergeAudioVideo, {
  showMergeAudioVideoHelp,
} from "../lib/merge-audio-video.mjs";
import { cleanOutputHistory } from "../lib/utils.mjs";
import { runGetPromotImageByVideo } from "../lib/get-promot-image-by-video.mjs";
import { runVoiceClone, listAvailableModels } from "../lib/voice-clone.mjs";
import runVideoDedup, { showVideoDedupHelp } from "../lib/video-dedup.mjs";
import runMergeOptions, {
  showMergeOptionsHelp,
} from "../lib/merge-options.mjs";
import config from "../config.mjs";

async function loadConfig() {
  try {
    return config;
  } catch (err) {
    console.warn("Warning: Could not load config.mjs:", err.message);
  }
  return {};
}

function printHelp() {
  console.log(
    `\nnode-ffmpeg-tools <command> [options]\n\nCommands:\n  down-rm-watermark [url]     Download mp4 and blur bottom-right watermark\n  history-person              Process history person video with titles and effects\n  ai-remove-watermark [url]   AI inpainting to remove watermark; keeps original resolution/fps\n  merge-video                 Merge multiple videos with transition effects\n  merge-options               Automated workflow: merge videos â†’ add titles â†’ move to outputUtils\n  clip-audio                  Clip audio files from specified start time\n  clip-video                  Clip video files with time range batch processing\n  extract-audio               Extract audio from video files with format conversion\n  merge-audio-video           Merge audio and video files with position control\n  auto-deepseek-jimeng        Automate DeepSeek chat to generate video prompts\n  jimeng-video-generator      Generate videos using Jimeng with batch image upload and shot descriptions\n  get-promot-image-by-video   Extract video frames, OCR text recognition, and generate prompts using AI\n  filter                      Apply various filters to videos (cinematic, vintage, artistic, etc.)\n  optimize-image                  Convert 2D video to 3D (anaglyph, side-by-side, top-bottom)\n  batch-crop-images           Batch crop images to 9:16 aspect ratio for social media\n  voice-clone                 Free voice cloning and text-to-speech using open-source models\n  video-dedup                 Video deduplication with sweep light, MD5 change, letterbox, sharpen, denoise, speed change\n  clear-browser-data          Clear saved browser login data for DeepSeek\n\nGlobal Options:\n  cleanOutputHistory          Automatically clean output directory before running commands (default: true)\n                              Set to false in config.mjs to disable: cleanOutputHistory: false\n\nOptions for get-promot-image-by-video:\n  --name, -n <name>       Update videoName in config.mjs and jimeng-video-config.mjs\n  Uses configuration from config.mjs under "get-promot-image-by-video" section.\n  Workflow: Extract video frames â†’ AI recognition â†’ Generate prompts â†’ Remove watermarks\n\nOptions for merge-options:\n  --name, -n <name>       Update jimeng-video-config.mjs name constant\n  --num <number>          Update all historyNum variables in project\n  Uses configuration from config.mjs under "merge-options" section.\n  Required config field: name (corresponds to output/{name}/processed_data.json)\n  Workflow: Read processed_data.json â†’ Update merge-video config â†’ Run merge-video â†’ \n            Update history-person config â†’ Run history-person â†’ Move final video to outputUtils\n\nOptions for voice-clone:\n  --list-models               List all available TTS models\n  Uses configuration from config.mjs under "voice-clone" section.\n  Supports three modes: "clone" (voice cloning), "tts" (batch text-to-speech), "single" (single TTS)\n\nOptions for batch-crop-images:\n  Uses configuration from config.mjs under "batch-crop-images" section.\n  Required config fields: inputDir (source directory), outputDir (destination directory)\n  Optional config fields: targetAspectRatio (default: "9:16"), cropMode (center/smart/entropy),\n                         quality (1-100, default: 90), outputFormat (auto/jpg/png/webp)\n\nExamples:\n  node-ffmpeg-tools get-promot-image-by-video --name "20251128-æå…‰è€€"  # Extract frames with custom name\n  node-ffmpeg-tools merge-options --name "20251128-æå…‰è€€" --num 11     # Run workflow with custom settings\n  node-ffmpeg-tools merge-options                                # Run automated video workflow\n  node-ffmpeg-tools voice-clone --list-models                    # List available TTS models\n  node-ffmpeg-tools voice-clone                                  # Run voice cloning from config.mjs\n  node-ffmpeg-tools batch-crop-images                            # Batch crop images to 9:16\n  node-ffmpeg-tools filter --list                               # List available video filters\n  node-ffmpeg-tools optimize-image --list                       # List available 3D conversion modes`
  );
}

(async () => {
  const [cmd, ...rest] = argv._ ?? [];

  // å¦‚æœæ²¡æœ‰å‘½ä»¤ï¼Œæˆ–è€…æ²¡æœ‰å‘½ä»¤ä½†æœ‰helpå‚æ•°ï¼Œæ˜¾ç¤ºé€šç”¨å¸®åŠ©
  if (!cmd || (!cmd && (argv.help || argv.h))) {
    printHelp();
    process.exit(1);
  }

  const config = await loadConfig();

  // éœ€è¦æ¸…ç†outputå†å²æ•°æ®çš„å‘½ä»¤åˆ—è¡¨
  const commandsNeedCleanup = [
    "down-rm-watermark",
    "history-person",
    "ai-remove-watermark",
    "merge-video",
    "merge-options",
    "clip-audio",
    "clip-video",
    "extract-audio",
    "merge-audio-video",
    "auto-deepseek-jimeng",
    "jimeng-video-generator",
    "get-promot-image-by-video",
    "filter",
    "optimize-image",
    "batch-crop-images",
    "voice-clone",
    "video-dedup",
  ];

  // å¦‚æœæ˜¯éœ€è¦æ¸…ç†çš„å‘½ä»¤ï¼Œå…ˆæ‰§è¡Œæ¸…ç†
  if (commandsNeedCleanup.includes(cmd)) {
    await cleanOutputHistory(config.cleanOutputHistory);
  }

  try {
    switch (cmd) {
      case "down-rm-watermark": {
        let url = argv.url || argv.u || rest[0];
        let bgMusic = argv["bg-music"] || argv.b;

        // If no URL provided, try to get from config
        if (!url && config["down-rm-watermark"]?.url) {
          url = config["down-rm-watermark"].url;
          console.log("Using URL from config.mjs");
        }
        // If no bg-music provided, try to get from config
        if (!bgMusic && config["down-rm-watermark"]?.["bg-music"]) {
          bgMusic = config["down-rm-watermark"]["bg-music"];
          console.log("Using bg-music from config.mjs");
        }

        if (!url) {
          console.error("\nUsage: node-ffmpeg-tools down-rm-watermark <url>");
          console.error(
            'Or add URL to config.mjs under "down-rm-watermark.url"'
          );
          process.exit(1);
        }
        await runDownRmWatermark(url, { bgMusic });
        break;
      }
      case "history-person": {
        if (!config["history-person"]) {
          console.error(
            '\nError: No "history-person" configuration found in config.mjs'
          );
          console.error(
            "Please add history-person configuration with url, title, sectionTitle, and bg-music fields"
          );
          process.exit(1);
        }

        console.log("Using history-person configuration from config.mjs");
        await runHistoryPerson(config["history-person"]);
        break;
      }
      case "ai-remove-watermark": {
        const aiConfig = config["ai-remove-watermark"];
        let url = argv.url || argv.u || rest[0];

        // æ”¯æŒæ‰¹é‡å¤„ç†æ¨¡å¼
        if (aiConfig && Array.isArray(aiConfig.videos)) {
          console.log("Using batch processing mode from config.mjs");
          await runAiRemoveWatermark(aiConfig);
          break;
        }

        // å‘åå…¼å®¹ï¼šå•è§†é¢‘æ¨¡å¼
        if (!url && aiConfig?.url) {
          url = aiConfig.url;
          console.log("Using URL from config.mjs (ai-remove-watermark.url)");
        }

        if (!url) {
          console.error("\nUsage: node-ffmpeg-tools ai-remove-watermark <url>");
          console.error(
            'Or configure in config.mjs under "ai-remove-watermark"'
          );
          console.error(
            '  Single video: { url: "path/to/video.mp4", mask: {...}, title: "...", titleAnimation: "..." }'
          );
          console.error(
            '  Batch mode: { videos: [{url: "...", mask: {...}}, ...], globalTitle: "...", globalTitleAnimation: "..." }'
          );
          process.exit(1);
        }

        await runAiRemoveWatermark(aiConfig || url);
        break;
      }
      case "merge-video": {
        if (!config["merge-video"]) {
          console.error(
            '\nError: No "merge-video" configuration found in config.mjs'
          );
          console.error(
            "Please add merge-video configuration with urls array and switch (transition effect) fields"
          );
          process.exit(1);
        }

        console.log("Using merge-video configuration from config.mjs");
        await runMergeVideo(config["merge-video"]);
        break;
      }
      case "clip-audio": {
        if (!config["clip-audio"]) {
          console.error(
            '\nError: No "clip-audio" configuration found in config.mjs'
          );
          console.error(
            "Please add clip-audio configuration as an array of {url, start?, duration?, output?} objects"
          );
          process.exit(1);
        }

        if (!Array.isArray(config["clip-audio"])) {
          console.error('\nError: "clip-audio" configuration must be an array');
          console.error(
            "Each item should have: {url, start?, duration?, output?}"
          );
          process.exit(1);
        }

        console.log("Using clip-audio configuration from config.mjs");
        await runClipAudio(config["clip-audio"]);
        break;
      }
      case "clip-video": {
        if (!config["clip-video"]) {
          console.error(
            '\nError: No "clip-video" configuration found in config.mjs'
          );
          console.error(
            "Please add clip-video configuration with videos array"
          );
          process.exit(1);
        }

        console.log("Using clip-video configuration from config.mjs");
        await runClipVideo(config["clip-video"]);
        break;
      }
      case "auto-deepseek-jimeng": {
        if (!config["auto-deepseek-jimeng"]) {
          console.error(
            '\nError: No "auto-deepseek-jimeng" configuration found in config.mjs'
          );
          console.error(
            "Please add auto-deepseek-jimeng configuration with deepseek settings"
          );
          process.exit(1);
        }

        console.log("Using auto-deepseek-jimeng configuration from config.mjs");
        await runAutoDeepseekJimeng(config["auto-deepseek-jimeng"]);
        break;
      }
      case "jimeng-video-generator": {
        if (!config["jimeng-video-generator"]) {
          console.error(
            '\nError: No "jimeng-video-generator" configuration found in config.mjs'
          );
          console.error(
            "Please add jimeng-video-generator configuration with required settings"
          );
          process.exit(1);
        }

        // æ£€æŸ¥æ˜¯å¦æœ‰ processed_data.json æ–‡ä»¶
        const processedDataPath =
          "./output/" +
          (config["jimeng-video-generator"].name || "default") +
          "/processed_data.json";
        let processedData;
        try {
          const fs = await import("fs/promises");
          const data = await fs.readFile(processedDataPath, "utf8");
          processedData = JSON.parse(data);
          console.log(
            `âœ… æ‰¾åˆ° processed_data.json æ–‡ä»¶ï¼ŒåŒ…å« ${processedData.segments?.length || 0} ä¸ªæ®µè½`
          );
        } catch (error) {
          console.error(
            `\nError: æ— æ³•è¯»å– processed_data.json æ–‡ä»¶: ${processedDataPath}`
          );
          console.error(
            "è¯·å…ˆè¿è¡Œ auto-deepseek-jimeng å‘½ä»¤ç”Ÿæˆæ•°æ®ï¼Œæˆ–æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®"
          );
          process.exit(1);
        }

        console.log(
          "Using jimeng-video-generator configuration from config.mjs"
        );
        await runJimengVideoFlow(
          config["jimeng-video-generator"],
          processedData,
          config["jimeng-video-generator"].name || "default"
        );
        break;
      }
      case "get-promot-image-by-video": {
        if (!config["get-promot-image-by-video"]) {
          console.error(
            '\nError: No "get-promot-image-by-video" configuration found in config.mjs'
          );
          console.error(
            "Please add get-promot-image-by-video configuration with videoPath, videoName, seconds, and other required settings"
          );
          process.exit(1);
        }

        console.log(
          "Using get-promot-image-by-video configuration from config.mjs"
        );
        
        // æ”¶é›†å‘½ä»¤è¡Œé€‰é¡¹
        const options = {
          name: argv.name || argv.n,  // --name æˆ– -n å‚æ•°
        };
        
        await runGetPromotImageByVideo(config["get-promot-image-by-video"], options);
        break;
      }
      case "filter": {
        // æ£€æŸ¥æ˜¯å¦è¦åˆ—å‡ºæ‰€æœ‰æ»¤é•œ
        if (argv.list || argv.l) {
          listFilters();
          break;
        }

        // ä»å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®æ–‡ä»¶è·å–è®¾ç½®
        const filterConfig = {
          input: argv.input || argv.i || rest[0] || config.filter?.input,
          output: argv.output || argv.o || config.filter?.output,
          preset: argv.preset || argv.p || config.filter?.preset,
          customFilter: argv.custom || argv.c || config.filter?.customFilter,
          quality: argv.quality || argv.q || config.filter?.quality || "high",
          keepAudio:
            argv["keep-audio"] !== false && config.filter?.keepAudio !== false,
        };

        if (!filterConfig.input) {
          console.error("\nError: è¯·æŒ‡å®šè¾“å…¥è§†é¢‘æ–‡ä»¶");
          console.error("ä½¿ç”¨æ–¹æ³•:");
          console.error(
            "  npx node-ffmpeg-tools filter --list                           # åˆ—å‡ºæ‰€æœ‰æ»¤é•œ"
          );
          console.error(
            "  npx node-ffmpeg-tools filter -i input.mp4 -p cinematic-warm  # ä½¿ç”¨é¢„è®¾æ»¤é•œ"
          );
          console.error(
            '  npx node-ffmpeg-tools filter -i input.mp4 -c "eq=contrast=1.2" # è‡ªå®šä¹‰æ»¤é•œ'
          );
          console.error("  æˆ–åœ¨ config.mjs ä¸­é…ç½® filter éƒ¨åˆ†\n");
          process.exit(1);
        }

        if (!filterConfig.preset && !filterConfig.customFilter) {
          console.error(
            "\nError: è¯·æŒ‡å®šé¢„è®¾æ»¤é•œ (--preset) æˆ–è‡ªå®šä¹‰æ»¤é•œ (--custom)"
          );
          console.error("ä½¿ç”¨ --list æŸ¥çœ‹æ‰€æœ‰å¯ç”¨çš„é¢„è®¾æ»¤é•œ\n");
          process.exit(1);
        }

        await runFilter(filterConfig);
        break;
      }
      case "optimize-image": {
        // æ£€æŸ¥æ˜¯å¦è¦åˆ—å‡ºæ‰€æœ‰3Dæ¨¡å¼
        if (argv.list || argv.l) {
          list3DModes();
          break;
        }

        // ä»å‘½ä»¤è¡Œå‚æ•°æˆ–é…ç½®æ–‡ä»¶è·å–è®¾ç½®
        const convert3DConfig = {
          input:
            argv.input || argv.i || rest[0] || config["optimize-image"]?.input,
          output: argv.output || argv.o || config["optimize-image"]?.output,
          mode:
            argv.mode ||
            argv.m ||
            config["optimize-image"]?.mode ||
            "anaglyph-red-cyan",
          depth: argv.depth || argv.d || config["optimize-image"]?.depth || 0.3,
          quality:
            argv.quality ||
            argv.q ||
            config["optimize-image"]?.quality ||
            "high",
          keepAudio:
            argv["keep-audio"] !== false &&
            config["optimize-image"]?.keepAudio !== false,
        };

        if (!convert3DConfig.input) {
          console.error("\nError: è¯·æŒ‡å®šè¾“å…¥è§†é¢‘æ–‡ä»¶");
          console.error("ä½¿ç”¨æ–¹æ³•:");
          console.error(
            "  npx node-ffmpeg-tools optimize-image --list                        # åˆ—å‡ºæ‰€æœ‰3Dæ¨¡å¼"
          );
          console.error(
            "  npx node-ffmpeg-tools optimize-image -i input.mp4 -m anaglyph-red-cyan  # è½¬æ¢ä¸ºçº¢è“3D"
          );
          console.error(
            "  npx node-ffmpeg-tools optimize-image -i input.mp4 -m side-by-side  # è½¬æ¢ä¸ºå·¦å³3D"
          );
          console.error("  æˆ–åœ¨ config.mjs ä¸­é…ç½® optimize-image éƒ¨åˆ†\n");
          process.exit(1);
        }

        await runConvert3D(convert3DConfig);
        break;
      }
      case "batch-crop-images": {
        if (!config["batch-crop-images"]) {
          console.error(
            '\nError: No "batch-crop-images" configuration found in config.mjs'
          );
          console.error(
            "Please add batch-crop-images configuration with inputDir and outputDir fields"
          );
          process.exit(1);
        }

        console.log("Using batch-crop-images configuration from config.mjs");
        await runBatchCropImages(config);
        break;
      }
      case "extract-audio": {
        // æ£€æŸ¥æ˜¯å¦è¦æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        if (argv.help || argv.h) {
          showExtractAudioHelp();
          break;
        }

        if (!config["extract-audio"]) {
          console.error(
            '\nError: No "extract-audio" configuration found in config.mjs'
          );
          console.error(
            "Please add extract-audio configuration with url and optional format/quality settings"
          );
          console.error("Or use --help to see configuration examples");
          process.exit(1);
        }

        console.log("Using extract-audio configuration from config.mjs");
        await runExtractAudio(config["extract-audio"]);
        break;
      }
      case "merge-audio-video": {
        // æ£€æŸ¥æ˜¯å¦è¦æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        if (argv.help || argv.h) {
          showMergeAudioVideoHelp();
          break;
        }

        if (!config["merge-audio-video"]) {
          console.error(
            '\nError: No "merge-audio-video" configuration found in config.mjs'
          );
          console.error(
            "Please add merge-audio-video configuration with videoUrl and audioUrl"
          );
          console.error("Or use --help to see configuration examples");
          process.exit(1);
        }

        console.log("Using merge-audio-video configuration from config.mjs");
        await runMergeAudioVideo(config["merge-audio-video"]);
        break;
      }
      case "voice-clone": {
        // æ£€æŸ¥æ˜¯å¦è¦åˆ—å‡ºæ‰€æœ‰TTSæ¨¡å‹
        if (argv["list-models"] || argv.l) {
          await listAvailableModels();
          break;
        }

        if (!config["voice-clone"]) {
          console.error(
            '\nError: No "voice-clone" configuration found in config.mjs'
          );
          console.error(
            "Please add voice-clone configuration with mode and required settings"
          );
          console.error("Supported modes:");
          console.error(
            '  "clone": Voice cloning with referenceAudio and targetTexts'
          );
          console.error('  "tts": Batch text-to-speech with texts array');
          console.error('  "single": Single text-to-speech with text string');
          console.error("Use --list-models to see available TTS models");
          process.exit(1);
        }

        console.log("Using voice-clone configuration from config.mjs");
        await runVoiceClone(config["voice-clone"]);
        break;
      }
      case "video-dedup": {
        // æ£€æŸ¥æ˜¯å¦è¦æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        if (argv.help || argv.h) {
          showVideoDedupHelp();
          break;
        }

        if (!config["video-dedup"]) {
          console.error(
            '\nError: No "video-dedup" configuration found in config.mjs'
          );
          console.error(
            "Please add video-dedup configuration with input and deduplication settings"
          );
          console.error("Use --help to see configuration examples");
          process.exit(1);
        }

        console.log("Using video-dedup configuration from config.mjs");
        await runVideoDedup(config["video-dedup"]);
        break;
      }
      case "merge-options": {
        // æ£€æŸ¥æ˜¯å¦è¦æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        if (argv.help || argv.h) {
          showMergeOptionsHelp();
          break;
        }

        if (!config["merge-options"]) {
          console.error(
            '\nError: No "merge-options" configuration found in config.mjs'
          );
          console.error(
            "Please add merge-options configuration with name field"
          );
          console.error("Example:");
          console.error('  "merge-options": {');
          console.error('    name: "20251128-äºšå†å±±å¤§äºŒä¸–"');
          console.error("  }");
          console.error("Use --help to see more information");
          process.exit(1);
        }

        console.log("Using merge-options configuration from config.mjs");
        
        // æ”¶é›†å‘½ä»¤è¡Œé€‰é¡¹
        const options = {
          name: argv.name || argv.n,  // --name æˆ– -n å‚æ•°
          num: argv.num ? parseInt(argv.num, 10) : undefined,  // --num å‚æ•°
        };
        
        await runMergeOptions(config["merge-options"], options);
        break;
      }
      case "clear-browser-data": {
        console.log("ğŸ§¹ æ­£åœ¨æ¸…ç†æµè§ˆå™¨ç”¨æˆ·æ•°æ®...");
        const success = await clearBrowserData();
        if (success) {
          console.log(
            "âœ… æµè§ˆå™¨æ•°æ®æ¸…ç†å®Œæˆï¼ä¸‹æ¬¡è¿è¡Œ auto-deepseek-jimeng æ—¶å°†éœ€è¦é‡æ–°ç™»å½•"
          );
        } else {
          console.log(
            "âŒ æµè§ˆå™¨æ•°æ®æ¸…ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™æˆ–æ‰‹åŠ¨åˆ é™¤ browser-data ç›®å½•"
          );
        }
        break;
      }
      default:
        console.error(`Unknown command: ${cmd}`);
        printHelp();
        process.exit(1);
    }
  } catch (err) {
    console.error("\nError:", err?.message || err);
    process.exit(1);
  }
})();
